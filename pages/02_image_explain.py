import streamlit as st
from openai import OpenAI
import base64
import os

from dotenv import load_dotenv
load_dotenv()

# openai
client = OpenAI()

PROMPT_FILE = "./prompts/01_ã‚µãƒ³ãƒ—ãƒ«.md"
UPLOAD_FOLDER = "./temp_upload"
UPLOAD_FILENAME = "uploaded_image"


def init_page():
    st.set_page_config(
        page_title="my gpt",
        page_icon="ğŸ“š"
    )
    st.title("gpt-4o chat")
    if "chat_log_02" not in st.session_state:
        st.session_state.chat_log_02 = []


def get_prompt(filepath):
    """ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾— """
    with open(filepath, "r", encoding="utf-8") as f:
        return f.read()


def prepare_directory(path):
    """ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã«ä½œæˆ """
    os.makedirs(path, exist_ok=True)


def png_upload():
    """ PNGãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ """
    uploaded_file = st.file_uploader(
        label = "ç”»åƒã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„",
        type = ["jpg", "jpeg", "png"],
        accept_multiple_files=False
    )
    prepare_directory(UPLOAD_FOLDER)

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPNGãƒ•ã‚¡ã‚¤ãƒ«ã‚’temp_pathã«ä¸Šæ›¸ãä¿å­˜
    if uploaded_file:
        file_extension = uploaded_file.name.split(".")[-1].lower()
        temp_path = os.path.join(UPLOAD_FOLDER, f"{UPLOAD_FILENAME}.{file_extension}")
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.read())
        return temp_path
    else:
        return None


def encode_image(temp_path):
    """ ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ """
    with open(temp_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def get_llm_response(query, temp_path):
    """ LLMã«ã‚¯ã‚¨ãƒªã‚’é€ä¿¡ã—ã€å›ç­”ã‚’å–å¾— """
    prompt = get_prompt(PROMPT_FILE)
    recent_log = st.session_state.chat_log_02
    base64_image = encode_image(temp_path)
    messages = [
        {"role":"system", "content": prompt}
    ]
    for entry in recent_log:
        if entry["name"] == "user":
            messages.append({
                "role": "user",
                "content": [
                    {"type": "text", "text": entry["msg"]},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{entry['image']}" }}
                ]
            })
        else:
            messages.append({"role": "assistant", "content": entry["msg"]})
    messages.append({
        "role": "user",
        "content": [
            {"type": "text", "text": query},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
        ]
    })
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0
    )
    answer = response.choices[0].message.content
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¨ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‚’ãƒ­ã‚°ã«è¿½åŠ 
    st.session_state.chat_log_02.append({"name" : "user", "msg" : query, "image": base64_image})
    st.session_state.chat_log_02.append({"name" : "assistant", "msg" : answer})
    return answer


def show_png(temp_path):
    """ å†™çœŸè¡¨ç¤º """
    st.image(temp_path)


def chat_interface(temp_path):
    """ ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ """
    # ãƒ­ã‚°è¡¨ç¤º
    for chat in st.session_state.chat_log_02:
        with st.chat_message(chat["name"]):
            st.write(chat["msg"])

    query = st.chat_input('å›ç­”ã‚’å…¥åŠ›')
    if query:
        answer = get_llm_response(query, temp_path)

        with st.chat_message("user"):
            st.write(query)

        with st.chat_message("assistant"):
            st.write(answer)


def main():
    init_page()
    temp_path = png_upload()
    if temp_path:
        show_png(temp_path)
        chat_interface(temp_path)


if __name__ == '__main__':
    main()